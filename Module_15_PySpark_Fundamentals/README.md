# Module 15: PySpark Fundamentals

**கற்க கசடற - Learn Flawlessly**

## Overview

Welcome to **Module 15: PySpark Fundamentals**! This module teaches you PySpark, the Python API for Apache Spark. You'll master DataFrame operations, transformations, actions, and SQL queries using PySpark - essential skills for modern data engineering at scale.

## Learning Objectives

1. **PySpark DataFrames**: Work with distributed DataFrames
2. **DataFrame Creation**: Create DataFrames from various sources
3. **Data Loading**: Read CSV, JSON, Parquet, databases
4. **DataFrame Operations**: Select, filter, sort, transform
5. **SQL Queries**: Query data using Spark SQL
6. **Aggregations**: GroupBy, agg(), and window functions
7. **Joins**: Inner, outer, left, right joins
8. **UDFs**: User-Defined Functions in PySpark
9. **Data Writing**: Save processed data
10. **Performance**: Optimization techniques

## Prerequisites

- Module 10-13: Python and SQL foundation
- Module 14: Apache Spark Introduction
- Understanding of Spark basics and RDDs

## Module Structure

### Theory Sections
1. Introduction to PySpark and SparkSession
2. Creating DataFrames
3. DataFrame schema and data types
4. Selecting and filtering data
5. DataFrame transformations
6. Aggregation operations
7. Joining DataFrames
8. Window functions
9. User-Defined Functions (UDFs)
10. Reading and writing data
11. Spark SQL integration
12. Performance optimization basics

### Labs
1. PySpark setup and SparkSession
2. Creating and exploring DataFrames
3. Data selection and filtering
4. Column operations and transformations
5. Aggregations and group by
6. Joining multiple DataFrames
7. Window functions
8. UDF creation and usage
9. Data I/O operations
10. Capstone: Complete PySpark data pipeline

## Real-World Applications

- Big data ETL pipelines
- Large-scale data transformations
- Real-time data processing
- Data lake operations
- Machine learning feature engineering
- Analytics on massive datasets

## Time Commitment: 40-50 hours

---

**கற்க கசடற** - Learn Flawlessly
